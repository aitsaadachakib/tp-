{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#part1\n",
    "1-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 12, 12, ..., 15, 15, 15],\n",
       "       [12, 12, 12, ..., 15, 15, 15],\n",
       "       [12, 12, 12, ..., 15, 15, 15],\n",
       "       ...,\n",
       "       [46, 46, 46, ..., 25, 25, 25],\n",
       "       [46, 45, 46, ..., 25, 25, 25],\n",
       "       [46, 46, 45, ..., 25, 25, 25]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_avant=cv2.imread(\"bob.PNG\",cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "image_avant[:]=image_avant[:]/2\n",
    "image_avant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def filterMiy(img, vois=20):\n",
    "    h, w = img.shape\n",
    "    imgmoy = np.zeros_like(img)\n",
    "\n",
    "    y = 0\n",
    "    while y < h:\n",
    "        x = 0\n",
    "        while x < w:\n",
    "            if (y < vois/2 or y > h-vois/2 or x < vois/2 or x > w-vois/2):\n",
    "                imgmoy[y, x] = img[y, x]\n",
    "            else:\n",
    "                imgv = img[y-int(vois/2):y+int(vois/2)+1, x-int(vois/2):x+int(vois/2)+1]\n",
    "                moy = np.mean(imgv)\n",
    "                imgmoy[y, x] = moy\n",
    "\n",
    "            x += 1\n",
    "        y += 1\n",
    "\n",
    "    return imgmoy\n",
    "\n",
    "def filterMed(img, vois=20):\n",
    "    h, w = img.shape\n",
    "    imgmed = np.zeros_like(img)\n",
    "\n",
    "    y = 0\n",
    "    while y < h:\n",
    "        x = 0\n",
    "        while x < w:\n",
    "            if (y < vois/2 or y > h-vois/2 or x < vois/2 or x > w-vois/2):\n",
    "                imgmed[y, x] = img[y, x]\n",
    "            else:\n",
    "                imgv = img[y-int(vois/2):y+int(vois/2)+1, x-int(vois/2):x+int(vois/2)+1]\n",
    "                t = np.sort(imgv.flatten())\n",
    "                imgmed[y, x] = t[int((vois*vois/2)+1)]\n",
    "\n",
    "            x += 1\n",
    "        y += 1\n",
    "\n",
    "    return imgmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def convolve(image, kernel):\n",
    "    height, width = image.shape\n",
    "    k_height, k_width = kernel.shape\n",
    "    pad_height = k_height // 2\n",
    "    pad_width = k_width // 2\n",
    "\n",
    "    # Create an empty output image with the same data type as the input image\n",
    "    output = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "    # Pad the input image\n",
    "    padded_image = cv2.copyMakeBorder(image, pad_height, pad_height, pad_width, pad_width, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    # Perform convolution without using range, sum, or np.sum\n",
    "    i = 0\n",
    "    while i < height:\n",
    "        j = 0\n",
    "        while j < width:\n",
    "            total_sum = 0\n",
    "            m = 0\n",
    "            while m < k_height:\n",
    "                n = 0\n",
    "                while n < k_width:\n",
    "                    total_sum += padded_image[i+m, j+n] * kernel[m, n]\n",
    "                    n += 1\n",
    "                m += 1\n",
    "            output[i, j] = total_sum\n",
    "            j += 1\n",
    "        i += 1\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16\n",
    "laplacian = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
    "\n",
    "image_gaussian=convolve(image_avant,gaussian)\n",
    "image_laplacian=convolve(image_gaussian,laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_filter(image, threshold=128):\n",
    "    height, width= image.shape\n",
    "\n",
    "    # Create an empty output image with the same width and height\n",
    "    output = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    i = 0\n",
    "    while i < height:\n",
    "        j = 0\n",
    "        while j < width:\n",
    "            # Extract intensity (grayscale value) from the pixel\n",
    "            intensity = image[i, j]\n",
    "\n",
    "            # Apply thresholding\n",
    "            if intensity > threshold:\n",
    "                output[i, j] = 255  # Set to white\n",
    "            else:\n",
    "                output[i, j] = 0    # Set to black\n",
    "\n",
    "            j += 1\n",
    "        i += 1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_threshold=threshold_filter(image_avant,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_filter(image):\n",
    "    height, width, channels = image.shape\n",
    "\n",
    "    # Create an empty output image with the same width and height\n",
    "    output = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    i = 0\n",
    "    while i < height:\n",
    "        j = 0\n",
    "        while j < width:\n",
    "            # Extract RGB values\n",
    "            r, g, b = image[i, j]\n",
    "\n",
    "            # Calculate grayscale value using a simple weighted sum\n",
    "            gray_value = int(0.299 * r + 0.587 * g + 0.114 * b)\n",
    "\n",
    "            # Set the grayscale value in the output image\n",
    "            output[i, j] = gray_value\n",
    "\n",
    "            j += 1\n",
    "        i += 1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_avant_c=cv2.imread(\"bob.PNG\")\n",
    "image_grayscale_filter=grayscale_filter(image_avant_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_erosion_filter(image, matrix_size):\n",
    "    filter_offset = (matrix_size - 1) // 2\n",
    "    morph_reset_value = 255\n",
    "\n",
    "    new_image = np.zeros_like(image)\n",
    "\n",
    "    for y in range(filter_offset, image.shape[0] - filter_offset):\n",
    "        for x in range(filter_offset, image.shape[1] - filter_offset):\n",
    "            roi = image[y - filter_offset:y + filter_offset + 1, x - filter_offset:x + filter_offset + 1]\n",
    "\n",
    "            blue = np.min(roi[:, :, 0])\n",
    "            green = np.min(roi[:, :, 1])\n",
    "            red = np.min(roi[:, :, 2])\n",
    "\n",
    "            new_image[y, x] = [blue, green, red]\n",
    "\n",
    "    return new_image\n",
    "# Create a structuring element\n",
    "eroded_image=apply_erosion_filter(image_avant_c,5)\n",
    "cv2.imshow('Original image', image_avant_c)\n",
    "cv2.imshow('Eroded image', eroded_image)\n",
    "\n",
    "# Wait for a key press to close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dilation_filter(image, matrix_size):\n",
    "    filter_offset = (matrix_size - 1) // 2\n",
    "    morph_reset_value = 0\n",
    "\n",
    "    new_image = np.zeros_like(image)\n",
    "\n",
    "    for y in range(filter_offset, image.shape[0] - filter_offset):\n",
    "        for x in range(filter_offset, image.shape[1] - filter_offset):\n",
    "            roi = image[y - filter_offset:y + filter_offset + 1, x - filter_offset:x + filter_offset + 1]\n",
    "\n",
    "            blue = np.max(roi[:, :, 0])\n",
    "            green = np.max(roi[:, :, 1])\n",
    "            red = np.max(roi[:, :, 2])\n",
    "\n",
    "            new_image[y, x] = [blue, green, red]\n",
    "\n",
    "    return new_image\n",
    "dilation_image=apply_dilation_filter(image_avant_c,5)\n",
    "cv2.imshow('Original image', image_avant_c)\n",
    "cv2.imshow('Eroded image', dilationfilter)\n",
    "\n",
    "# Wait for a key press to close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_opening_filter(image, matrix_size):\n",
    "    # Erosion\n",
    "    eroded_image = apply_erosion_filter(image, matrix_size)\n",
    "    \n",
    "    # Dilation\n",
    "    opened_image = apply_dilation_filter(eroded_image, matrix_size)\n",
    "    \n",
    "    return opened_image\n",
    "\n",
    "opening_image=apply_opening_filter(image_avant_c,5)\n",
    "cv2.imshow('Original image', image_avant_c)\n",
    "cv2.imshow('Eroded image', opening_image)\n",
    "\n",
    "# Wait for a key press to close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_closing_filter(image, matrix_size):\n",
    "    # Dilation\n",
    "    dilated_image = apply_dilation_filter(image, matrix_size)\n",
    "    \n",
    "    # Erosion\n",
    "    closed_image = apply_erosion_filter(dilated_image, matrix_size)\n",
    "\n",
    "    return closed_image\n",
    "\n",
    "closing_image=apply_closing_filter(image_avant_c,5)\n",
    "cv2.imshow('Original image', image_avant_c)\n",
    "cv2.imshow('Eroded image', closing_image)\n",
    "\n",
    "# Wait for a key press to close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_morphological_gradient(image, matrix_size):\n",
    "    # Dilation\n",
    "    dilated_image = apply_dilation_filter(image, matrix_size)\n",
    "    # Erosion\n",
    "    eroded_image = apply_erosion_filter(image, matrix_size)\n",
    "    # Morphological gradient (difference between dilation and erosion)\n",
    "    gradient_image = dilated_image - eroded_image\n",
    "    \n",
    "    return gradient_image\n",
    "gradient_image=apply_morphological_gradient(image_avant_c,5)\n",
    "cv2.imshow('Original image', image_avant_c)\n",
    "cv2.imshow('Eroded image', gradient_image)\n",
    "\n",
    "# Wait for a key press to close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_top_hat_transform(image, matrix_size):\n",
    "    # Structuring element for morphological operations\n",
    "    kernel = np.ones((matrix_size, matrix_size), dtype=np.uint8)\n",
    "\n",
    "    # Perform opening operation\n",
    "    opened_image = apply_opening_filter(image, matrix_size)\n",
    "    # Top-hat transform (difference between the original image and its opening)\n",
    "    top_hat_image = image-opened_image\n",
    "\n",
    "    return top_hat_image\n",
    "\n",
    "top_hat_image=apply_top_hat_transform(image_avant_c,5)\n",
    "cv2.imshow('Original image', image_avant_c)\n",
    "cv2.imshow('Eroded image', top_hat_image)\n",
    "\n",
    "# Wait for a key press to close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_black_hat_transform(image, matrix_size):\n",
    "\n",
    "    closed_image = apply_closing_filter(image, matrix_size)\n",
    "\n",
    "    # Black-hat transform (difference between the closing of the original image and the original image)\n",
    "    black_hat_image = closed_image-image\n",
    "\n",
    "    return black_hat_image\n",
    "black_hat_image=apply_black_hat_transform(image_avant_c,5)\n",
    "cv2.imshow('Original image', image_avant_c)\n",
    "cv2.imshow('Eroded image', black_hat_image)\n",
    "\n",
    "# Wait for a key press to close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mosaic(image, factor):\n",
    "    # Get image dimensions\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Create an empty image for the mosaic effect\n",
    "    mosaic_image = np.zeros_like(image)\n",
    "\n",
    "    # Iterate over mosaic blocks and set each block to the average color of its pixels\n",
    "    for i in range(0, height, factor):\n",
    "        for j in range(0, width, factor):\n",
    "            block = image[i:i+factor, j:j+factor]\n",
    "            average_color = np.mean(block, axis=(0, 1), dtype=np.uint8)\n",
    "            mosaic_image[i:i+factor, j:j+factor] = average_color\n",
    "\n",
    "    return mosaic_image\n",
    "\n",
    "mosaic_image=apply_mosaic(image_avant_c,1)\n",
    "cv2.imshow('Original image', image_avant_c)\n",
    "cv2.imshow('Eroded image', mosaic_image)\n",
    "\n",
    "# Wait for a key press to close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_motion_blur(image, kernel_size):\n",
    "    # Create a motion blur kernel\n",
    "    kernel = np.zeros((kernel_size, kernel_size))\n",
    "    kernel[:, int((kernel_size-1)/2)] = np.ones(kernel_size) / kernel_size\n",
    "\n",
    "    # Apply the motion blur filter without using .convolve\n",
    "    motion_blur_image = np.zeros_like(image, dtype=np.float32)\n",
    "    for i in range(image.shape[2]):  # Iterate over color channels\n",
    "        motion_blur_image[:, :, i] = np.convolve(image[:, :, i].flatten(), kernel[:, int((kernel_size-1)/2)], mode='same').reshape(image.shape[:2])\n",
    "\n",
    "    return motion_blur_image.astype(np.uint8)\n",
    "motion_blur_image=apply_motion_blur(image_avant_c,5)\n",
    "cv2.imshow('Original image', image_avant_c)\n",
    "cv2.imshow('Eroded image', motion_blur_image)\n",
    "\n",
    "# Wait for a key press to close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_color_detection(image, lower_color, upper_color):\n",
    "    # Convertir l'image de BGR à HSV (Espace de couleur Hue, Saturation, Value)\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Créer un masque en utilisant la plage de couleurs spécifiée\n",
    "    color_mask = cv2.inRange(hsv_image, lower_color, upper_color)\n",
    "\n",
    "    # Appliquer le masque à l'image d'origine pour ne conserver que les pixels de l'objet\n",
    "    result_image = cv2.bitwise_and(image, image, mask=color_mask)\n",
    "\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_green = np.array([40, 40, 40])\n",
    "upper_green = np.array([80, 255, 255])\n",
    "result = object_color_detection(image_avant_c, lower_green, upper_green)\n",
    "cv2.imshow('Original Image', image_avant_c)\n",
    "cv2.imshow('Color Detection Result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Object_Color_Detection(image, color_range):\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper bounds of the color range\n",
    "    lower_bound = np.array(color_range[0])\n",
    "    upper_bound = np.array(color_range[1])\n",
    "\n",
    "    # Create a mask for the desired color\n",
    "    mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "\n",
    "    # Fill holes in the mask\n",
    "    filled_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "\n",
    "    # Find the average color of the object\n",
    "    average_color = cv2.mean(image, filled_mask)[:3].astype(np.uint8)\n",
    "\n",
    "    # Find the bounding box of the object\n",
    "    bounding_box = None\n",
    "    for i in range(0, mask.shape[0]):\n",
    "        for j in range(0, mask.shape[1]):\n",
    "            if mask[i, j] == 255:\n",
    "                if bounding_box is None:\n",
    "                    bounding_box = [i, j, i, j]\n",
    "                else:\n",
    "                    bounding_box[0] = min(bounding_box[0], i)\n",
    "                    bounding_box[1] = min(bounding_box[1], j)\n",
    "                    bounding_box[2] = max(bounding_box[2], i)\n",
    "                    bounding_box[3] = max(bounding_box[3], j)\n",
    "\n",
    "    # Draw the bounding box on the image\n",
    "    if bounding_box is not None:\n",
    "        cv2.rectangle(image, (bounding_box[1], bounding_box[0]), (bounding_box[3], bounding_box[2]), (0, 255, 0), 3)\n",
    "\n",
    "    return image, average_color\n",
    "\n",
    "\n",
    "def detect_inrange(image, low, high, min_area, max_area):\n",
    "    points = []\n",
    "\n",
    "    image = cv2.blur(image, (5, 5))\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv_image, low, high)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if min_area < area < max_area:\n",
    "            (x, y), radius = cv2.minEnclosingCircle(contour)\n",
    "            points.append((int(x), int(y), int(radius), int(area)))\n",
    "\n",
    "    return image, mask, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chakib\\Desktop\\tp s3\\tp vision\\projet tp\\project.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chakib/Desktop/tp%20s3/tp%20vision/projet%20tp/project.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m color_range \u001b[39m=\u001b[39m [(\u001b[39m0\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m100\u001b[39m), (\u001b[39m100\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m255\u001b[39m)]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chakib/Desktop/tp%20s3/tp%20vision/projet%20tp/project.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m detected_image \u001b[39m=\u001b[39m Object_Color_Detection(image_avant_c, color_range)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chakib/Desktop/tp%20s3/tp%20vision/projet%20tp/project.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mDetected Image\u001b[39m\u001b[39m'\u001b[39m, detected_image)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chakib/Desktop/tp%20s3/tp%20vision/projet%20tp/project.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\chakib\\Desktop\\tp s3\\tp vision\\projet tp\\project.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chakib/Desktop/tp%20s3/tp%20vision/projet%20tp/project.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m filled_mask \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mmorphologyEx(mask, cv2\u001b[39m.\u001b[39mMORPH_CLOSE, np\u001b[39m.\u001b[39mones((\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m), np\u001b[39m.\u001b[39muint8))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chakib/Desktop/tp%20s3/tp%20vision/projet%20tp/project.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Find the average color of the object\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chakib/Desktop/tp%20s3/tp%20vision/projet%20tp/project.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m average_color \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mmean(image, filled_mask)[:\u001b[39m3\u001b[39;49m]\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39muint8)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chakib/Desktop/tp%20s3/tp%20vision/projet%20tp/project.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Find the bounding box of the object\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chakib/Desktop/tp%20s3/tp%20vision/projet%20tp/project.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m bounding_box \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "color_range = [(0, 100, 100), (100, 255, 255)]\n",
    "detected_image = Object_Color_Detection(image_avant_c, color_range)\n",
    "cv2.imshow('Detected Image', detected_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
